ğŸ“˜ Social Support AI â€“ Multimodal Eligibility System

This project implements a multimodal AI pipeline that ingests documents (PDF, Excel, DOCX, Image), extracts features, runs ML eligibility checks + LLM reasoning, and provides recommendations through a Streamlit chatbot interface.

âš™ï¸ 1. Prerequisites

Python 3.10+ (recommended: 3.10 or 3.11)

pip (Python package installer)

Git (to clone repo)

Ollama (for local LLM hosting, e.g., gemma:2b or llama2)

LangSmith account (optional, for observability)

ğŸ—ï¸ 2. Setup Virtual Environment
# Create venv
python -m venv venv

# Activate venv (Windows)
venv\Scripts\activate

# Activate venv (Linux/Mac)
source venv/bin/activate

ğŸ“¦ 3. Install Required Libraries

Install all dependencies:

pip install -r requirements.txt


If you donâ€™t have a requirements.txt yet, create one with these libraries:

streamlit
pandas
numpy
scikit-learn
joblib
python-docx
pytesseract
pillow
openpyxl
PyMuPDF   # (fitz for PDFs)
langgraph
ollama
requests
langsmith

ğŸ“‚ 4. Project Structure
social-support-ai/
â”‚â”€â”€ agents_orchestration.py   # LangGraph pipeline orchestration
â”‚â”€â”€ chatbot_demo.py            # Streamlit chatbot UI
â”‚â”€â”€ eligibility.py             # Feature extraction + ML eligibility
â”‚â”€â”€ ingestion.py               # Data ingestion (Excel, PDF, Image, DOCX)
â”‚â”€â”€ ml_model.py                # Training RandomForest & saving eligibility_model.pkl
â”‚â”€â”€ recommendations.py         # Rule-based recommendations
â”‚â”€â”€ run_eligibility.py         # CLI runner
â”‚â”€â”€ langsmith_logger.py        # LangSmith observability logger
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â”‚
â”œâ”€â”€ data/                      # All input files go here
â”‚   â”œâ”€â”€ excel/                 # Upload assets/liabilities excel
â”‚   â”œâ”€â”€ pdf/                   # Bank statements
â”‚   â”œâ”€â”€ images/                # Emirates ID images
â”‚   â”œâ”€â”€ resumes/               # DOCX resumes
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ eligibility_model.pkl  # Trained ML model
â”‚
â””â”€â”€ manual_checks.log          # Log for admin/manual checks

ğŸ§‘â€ğŸ« 5. Train the Model

If you want to retrain the eligibility model:

python ml_model.py


This will generate eligibility_model.pkl inside models/.

ğŸš€ 6. Run the Application
6.1 Start Ollama server (new terminal)
ollama serve

6.2 Run Streamlit chatbot
streamlit run chatbot_demo.py


Open the app at http://localhost:8501

ğŸ”— 7. Using the Application

Upload 4 files:

Excel (Assets & Liabilities)

PDF (Bank Statement)

Image (Emirates ID)

DOCX (Resume)

The system will:

Ingest and parse data

Extract features

Run ML eligibility model

Generate LLM reasoning trace (via Ollama)

Provide decision + recommendations

ğŸ“Š 8. Observability with LangSmith

To enable LangSmith logging:

export LANGSMITH_API_KEY="your_api_key_here"


Windows PowerShell:

setx LANGSMITH_API_KEY "your_api_key_here"


Traces will appear in your LangSmith dashboard.
